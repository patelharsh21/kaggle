{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae937fe",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:23.104332Z",
     "iopub.status.busy": "2024-12-12T10:21:23.104029Z",
     "iopub.status.idle": "2024-12-12T10:21:24.758739Z",
     "shell.execute_reply": "2024-12-12T10:21:24.757403Z"
    },
    "papermill": {
     "duration": 1.661861,
     "end_time": "2024-12-12T10:21:24.760964",
     "exception": false,
     "start_time": "2024-12-12T10:21:23.099103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fight-detection/dataset/videos.txt\n",
      "/kaggle/input/fight-detection/dataset/fight/fi141.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi034.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi067.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi135.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi100.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi066.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi124.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi143.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi027.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi080.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi116.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi136.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi030.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi003.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi062.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi002.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi104.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi115.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi113.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi049.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi029.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi043.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi109.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi112.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi085.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi076.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi065.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi142.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi088.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi138.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi061.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi064.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi004.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi006.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi149.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi082.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi024.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi040.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi078.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi023.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi051.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi068.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi118.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi102.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi096.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi094.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi120.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi137.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi059.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi083.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi146.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi072.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi121.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi011.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi131.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi081.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi005.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi009.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi008.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi060.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi108.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi036.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi063.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi117.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi025.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi071.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi145.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi122.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi086.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi148.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi041.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi057.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi134.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi017.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi031.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi110.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi140.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi106.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi016.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi101.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi097.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi075.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi129.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi045.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi107.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi099.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi093.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi019.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi053.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi105.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi039.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi147.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi054.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi127.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi103.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi130.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi021.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi012.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi125.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi074.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi150.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi028.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi033.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi123.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi038.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi098.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi014.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi128.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi022.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi114.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi090.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi001.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi119.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi132.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi126.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi070.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi089.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi007.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi077.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi037.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi087.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi047.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi092.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi044.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi013.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi015.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi073.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi010.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi055.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi111.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi084.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi046.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi058.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi050.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi069.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi048.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi042.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi035.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi052.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi026.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi133.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi018.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi032.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi079.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi144.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi056.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi091.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi139.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi095.mp4\n",
      "/kaggle/input/fight-detection/dataset/fight/fi020.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi048.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi017.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi088.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi138.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi113.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi080.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi116.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi131.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi108.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi105.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi025.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi057.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi081.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi044.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi034.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi028.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi040.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi098.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi119.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi073.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi010.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi059.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi041.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi145.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi149.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi050.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi095.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi087.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi118.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi013.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi136.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi067.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi029.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi112.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi019.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi110.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi047.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi140.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi101.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi103.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi005.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi091.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi130.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi142.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi090.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi012.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi086.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi075.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi150.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi070.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi024.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi007.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi092.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi038.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi004.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi141.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi001.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi042.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi093.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi148.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi018.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi008.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi097.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi078.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi096.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi026.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi032.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi139.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi006.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi147.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi014.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi133.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi082.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi009.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi020.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi122.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi089.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi063.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi077.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi106.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi099.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi120.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi060.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi117.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi134.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi085.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi011.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi111.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi083.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi015.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi128.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi084.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi036.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi055.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi094.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi058.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi144.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi125.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi079.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi033.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi054.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi016.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi039.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi021.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi064.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi027.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi022.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi069.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi003.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi121.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi127.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi104.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi030.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi056.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi107.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi123.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi074.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi143.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi046.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi114.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi031.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi135.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi071.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi035.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi037.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi065.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi124.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi023.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi061.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi129.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi002.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi052.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi146.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi126.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi049.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi062.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi068.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi045.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi053.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi137.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi100.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi066.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi132.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi072.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi043.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi115.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi076.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi051.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi102.mp4\n",
      "/kaggle/input/fight-detection/dataset/noFight/nofi109.mp4\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bfacddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:24.769702Z",
     "iopub.status.busy": "2024-12-12T10:21:24.769308Z",
     "iopub.status.idle": "2024-12-12T10:21:41.546010Z",
     "shell.execute_reply": "2024-12-12T10:21:41.544889Z"
    },
    "papermill": {
     "duration": 16.783253,
     "end_time": "2024-12-12T10:21:41.548168",
     "exception": false,
     "start_time": "2024-12-12T10:21:24.764915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -q pytorchvideo transformers evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d02e439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:41.557508Z",
     "iopub.status.busy": "2024-12-12T10:21:41.556861Z",
     "iopub.status.idle": "2024-12-12T10:21:45.974494Z",
     "shell.execute_reply": "2024-12-12T10:21:45.973451Z"
    },
    "papermill": {
     "duration": 4.424315,
     "end_time": "2024-12-12T10:21:45.976358",
     "exception": false,
     "start_time": "2024-12-12T10:21:41.552043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths to your dataset\n",
    "fight_path_template = '/kaggle/input/fight-detection/dataset/fight/fi{num:03d}.mp4'\n",
    "nofight_path_template = '/kaggle/input/fight-detection/dataset/noFight/nofi{num:03d}.mp4'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c60cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:45.986613Z",
     "iopub.status.busy": "2024-12-12T10:21:45.986234Z",
     "iopub.status.idle": "2024-12-12T10:22:27.550393Z",
     "shell.execute_reply": "2024-12-12T10:22:27.549693Z"
    },
    "papermill": {
     "duration": 41.572058,
     "end_time": "2024-12-12T10:22:27.552391",
     "exception": false,
     "start_time": "2024-12-12T10:21:45.980333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class DataLoading:\n",
    "    def load_video_with_resizing_and_frame_handling(self, video_path, target_frames=16, target_size=(224, 224)):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {video_path}\")\n",
    "            return None\n",
    "\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            resized_frame = cv2.resize(frame, target_size)\n",
    "            normalized_frame = resized_frame / 255.0\n",
    "            frames.append(normalized_frame)\n",
    "\n",
    "        cap.release()\n",
    "        video_tensor = np.array(frames)\n",
    "\n",
    "        num_frames = video_tensor.shape[0]\n",
    "        if num_frames > target_frames:\n",
    "            indices = np.linspace(0, num_frames - 1, target_frames).astype(int)\n",
    "            video_tensor = video_tensor[indices]\n",
    "        elif num_frames < target_frames:\n",
    "            pad_length = target_frames - num_frames\n",
    "            padding = np.zeros((pad_length, target_size[0], target_size[1], 3))\n",
    "            video_tensor = np.concatenate((video_tensor, padding), axis=0)\n",
    "        return video_tensor  # numpy array\n",
    "\n",
    "    def get_data(self):\n",
    "        num_samples = 150\n",
    "        data = []\n",
    "        labels = []\n",
    "        count = 0\n",
    "        for i in range(1, num_samples + 1):\n",
    "            video_path = fight_path_template.format(num=i)\n",
    "            video_tensor = self.load_video_with_resizing_and_frame_handling(video_path)\n",
    "            if video_tensor is not None:\n",
    "                count += 1\n",
    "                data.append(video_tensor)\n",
    "                labels.append(1)  # Fight label\n",
    "\n",
    "        for i in range(1, num_samples + 1):\n",
    "            video_path = nofight_path_template.format(num=i)\n",
    "            video_tensor = self.load_video_with_resizing_and_frame_handling(video_path)\n",
    "            if video_tensor is not None:\n",
    "                count += 1\n",
    "                data.append(video_tensor)\n",
    "                labels.append(0)  # NoFight label\n",
    "        return data, labels\n",
    "\n",
    "# Instantiate and load data\n",
    "instance = DataLoading()\n",
    "data, labels = instance.get_data()\n",
    "\n",
    "# Convert to tensors\n",
    "data = np.array(data)  # Shape: [300, 32, 112, 112, 3]\n",
    "data = np.transpose(data,(0, 1, 4, 2, 3) )\n",
    "\n",
    "labels = np.array(labels)  # Shape: [300]\n",
    "\n",
    "# tensor_X = torch.tensor(data)\n",
    "# tensor_Y = torch.tensor(labels)\n",
    "\n",
    "# # Split into training and testing sets (80% train, 20% test)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     tensor_X, tensor_Y, test_size=0.2, random_state=1, stratify=tensor_Y\n",
    "# )\n",
    "\n",
    "# # Permute the tensors to [batch_size, channels, depth, height, width]\n",
    "# X_train = X_train.permute(0, 4, 1, 2, 3).float()  # Shape: [240, 3, 32, 112, 112]\n",
    "# X_test = X_test.permute(0, 4, 1, 2, 3).float()    # Shape: [60, 3, 32, 112, 112]\n",
    "\n",
    "# # Ensure labels are integers for CrossEntropyLoss\n",
    "# y_train = y_train.long()  # Shape: [240]\n",
    "# y_test = y_test.long()    # Shape: [60]\n",
    "\n",
    "# class VideoDataset(Dataset):\n",
    "#     def __init__(self, videos, labels):\n",
    "#         self.videos = videos  # Tensor containing video data [batch, 3, 32, 112, 112]\n",
    "#         self.labels = labels  # Tensor containing labels [batch]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.videos)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         video = self.videos[idx]    # [3, 32, 112, 112]\n",
    "#         label = self.labels[idx]    # Scalar int (0 or 1)\n",
    "#         return {\"video\": video, \"label\": label}\n",
    "\n",
    "# # Create Dataset instances\n",
    "# dataset_train = VideoDataset(X_train, y_train)\n",
    "# dataset_test = VideoDataset(X_test, y_test)\n",
    "\n",
    "# # Create DataLoader instances (optional, if you prefer using DataLoader instead of Hugging Face Datasets)\n",
    "# batch_size = 2\n",
    "# data_loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "# data_loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a7cc7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:22:27.561451Z",
     "iopub.status.busy": "2024-12-12T10:22:27.560923Z",
     "iopub.status.idle": "2024-12-12T10:22:28.349954Z",
     "shell.execute_reply": "2024-12-12T10:22:28.349069Z"
    },
    "papermill": {
     "duration": 0.796155,
     "end_time": "2024-12-12T10:22:28.352547",
     "exception": false,
     "start_time": "2024-12-12T10:22:27.556392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "# Convert tensors to numpy for Hugging Face Dataset\n",
    "def tensor_to_numpy(videos, labels):\n",
    "    lst = []\n",
    "    for i in range(0, len(videos) - 29, 30):\n",
    "        lst.append({\"video\": videos[i:i + 30], \"label\": labels[i:i + 30]})\n",
    "    return lst\n",
    "\n",
    "# Convert tensors and split with randomness\n",
    "lst = tensor_to_numpy(data, labels)\n",
    "\n",
    "# Shuffle the list randomly\n",
    "random.shuffle(lst)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_split = int(0.8 * len(lst))  # 80% for training, 20% for testing\n",
    "train_dict_list = lst[:train_split]\n",
    "test_dict_list = lst[train_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87097e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:22:28.364300Z",
     "iopub.status.busy": "2024-12-12T10:22:28.363496Z",
     "iopub.status.idle": "2024-12-12T10:22:28.372975Z",
     "shell.execute_reply": "2024-12-12T10:22:28.371843Z"
    },
    "papermill": {
     "duration": 0.017589,
     "end_time": "2024-12-12T10:22:28.375347",
     "exception": false,
     "start_time": "2024-12-12T10:22:28.357758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec12b93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:22:28.385816Z",
     "iopub.status.busy": "2024-12-12T10:22:28.385556Z",
     "iopub.status.idle": "2024-12-12T10:23:45.953507Z",
     "shell.execute_reply": "2024-12-12T10:23:45.952822Z"
    },
    "papermill": {
     "duration": 77.574403,
     "end_time": "2024-12-12T10:23:45.955594",
     "exception": false,
     "start_time": "2024-12-12T10:22:28.381191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf_train_dataset_list=[]\n",
    "for train_dict in train_dict_list :\n",
    "    hf_train_dataset_list.append(HFDataset.from_dict(train_dict))\n",
    "hf_test_dataset_list=[]\n",
    "for test_dict in lst :\n",
    "    hf_test_dataset_list.append(HFDataset.from_dict(test_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ede779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:23:45.965307Z",
     "iopub.status.busy": "2024-12-12T10:23:45.964576Z",
     "iopub.status.idle": "2024-12-12T10:23:46.014738Z",
     "shell.execute_reply": "2024-12-12T10:23:46.013908Z"
    },
    "papermill": {
     "duration": 0.056738,
     "end_time": "2024-12-12T10:23:46.016511",
     "exception": false,
     "start_time": "2024-12-12T10:23:45.959773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "merged_dataset_train=hf_train_dataset_list[0]\n",
    "for i in range(1,len(hf_train_dataset_list)) :\n",
    "    merged_dataset_train=concatenate_datasets([merged_dataset_train,hf_train_dataset_list[i]])\n",
    "\n",
    "merged_dataset_test=hf_test_dataset_list[0]\n",
    "for i in range(1,len(hf_test_dataset_list)) :\n",
    "    merged_dataset_test=concatenate_datasets([merged_dataset_test,hf_test_dataset_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e236b41b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:23:46.025233Z",
     "iopub.status.busy": "2024-12-12T10:23:46.024959Z",
     "iopub.status.idle": "2024-12-12T10:23:46.031647Z",
     "shell.execute_reply": "2024-12-12T10:23:46.031074Z"
    },
    "papermill": {
     "duration": 0.012877,
     "end_time": "2024-12-12T10:23:46.033225",
     "exception": false,
     "start_time": "2024-12-12T10:23:46.020348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename 'video' key to match the expected input by VideoMAE\n",
    "hf_train_dataset = merged_dataset_train.rename_column(\"video\", \"pixel_values\")  #what does this functions do\n",
    "hf_test_dataset = merged_dataset_test.rename_column(\"video\", \"pixel_values\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c64389d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:23:46.041619Z",
     "iopub.status.busy": "2024-12-12T10:23:46.041364Z",
     "iopub.status.idle": "2024-12-12T10:23:46.046285Z",
     "shell.execute_reply": "2024-12-12T10:23:46.045474Z"
    },
    "papermill": {
     "duration": 0.010866,
     "end_time": "2024-12-12T10:23:46.047818",
     "exception": false,
     "start_time": "2024-12-12T10:23:46.036952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pixel_values', 'label'],\n",
       "    num_rows: 240\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c9e0e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:23:46.056021Z",
     "iopub.status.busy": "2024-12-12T10:23:46.055806Z",
     "iopub.status.idle": "2024-12-12T10:23:46.059460Z",
     "shell.execute_reply": "2024-12-12T10:23:46.058671Z"
    },
    "papermill": {
     "duration": 0.009575,
     "end_time": "2024-12-12T10:23:46.061076",
     "exception": false,
     "start_time": "2024-12-12T10:23:46.051501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define label mappings\n",
    "label2id = {\"noFight\": 0, \"fight\": 1}\n",
    "id2label = {0: \"noFight\", 1: \"fight\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f44bbae",
   "metadata": {
    "papermill": {
     "duration": 0.0035,
     "end_time": "2024-12-12T10:23:46.068318",
     "exception": false,
     "start_time": "2024-12-12T10:23:46.064818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c06e5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:23:46.076562Z",
     "iopub.status.busy": "2024-12-12T10:23:46.076325Z",
     "iopub.status.idle": "2024-12-12T10:23:59.539555Z",
     "shell.execute_reply": "2024-12-12T10:23:59.538450Z"
    },
    "papermill": {
     "duration": 13.469679,
     "end_time": "2024-12-12T10:23:59.541671",
     "exception": false,
     "start_time": "2024-12-12T10:23:46.071992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\r\n",
      "  Downloading mlflow-2.19.0-py3-none-any.whl.metadata (30 kB)\r\n",
      "Collecting mlflow-skinny==2.19.0 (from mlflow)\r\n",
      "  Downloading mlflow_skinny-2.19.0-py3-none-any.whl.metadata (31 kB)\r\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.0.3)\r\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.4)\r\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.13.3)\r\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (7.1.0)\r\n",
      "Collecting graphene<4 (from mlflow)\r\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Collecting gunicorn<24 (from mlflow)\r\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.6)\r\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.7.5)\r\n",
      "Requirement already satisfied: numpy<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.26.4)\r\n",
      "Requirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.2)\r\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (16.1.0)\r\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.2.2)\r\n",
      "Requirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.14.1)\r\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.0.30)\r\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.19.0->mlflow)\r\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (3.0.0)\r\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.19.0->mlflow)\r\n",
      "  Downloading databricks_sdk-0.39.0-py3-none-any.whl.metadata (38 kB)\r\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (3.1.43)\r\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (7.0.0)\r\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (1.25.0)\r\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (1.25.0)\r\n",
      "Requirement already satisfied: packaging<25 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (21.3)\r\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (3.20.3)\r\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (6.0.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (2.32.3)\r\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.19.0->mlflow) (0.5.0)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.18)\r\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.4)\r\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\r\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (1.8.2)\r\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\r\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\r\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (2.9.0.post0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.1.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.5.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\r\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (2.30.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (4.0.11)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.19.0->mlflow) (3.19.2)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (1.2.14)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (0.46b0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (2024.8.30)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (1.16.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (5.0.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (0.4.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (4.9)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (0.6.0)\r\n",
      "Downloading mlflow-2.19.0-py3-none-any.whl (27.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mlflow_skinny-2.19.0-py3-none-any.whl (5.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\r\n",
      "Downloading databricks_sdk-0.39.0-py3-none-any.whl (622 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m623.0/623.0 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\r\n",
      "Installing collected packages: graphql-core, cachetools, gunicorn, graphql-relay, graphene, databricks-sdk, mlflow-skinny, mlflow\r\n",
      "  Attempting uninstall: cachetools\r\n",
      "    Found existing installation: cachetools 4.2.4\r\n",
      "    Uninstalling cachetools-4.2.4:\r\n",
      "      Successfully uninstalled cachetools-4.2.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 24.8.3 requires cubinlinker, which is not installed.\r\n",
      "cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 24.8.3 requires ptxcompiler, which is not installed.\r\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed cachetools-5.3.3 databricks-sdk-0.39.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.19.0 mlflow-skinny-2.19.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec1945e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:23:59.554859Z",
     "iopub.status.busy": "2024-12-12T10:23:59.554542Z",
     "iopub.status.idle": "2024-12-12T10:24:20.758638Z",
     "shell.execute_reply": "2024-12-12T10:24:20.757961Z"
    },
    "papermill": {
     "duration": 21.213058,
     "end_time": "2024-12-12T10:24:20.760591",
     "exception": false,
     "start_time": "2024-12-12T10:23:59.547533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea30b3cd28c74974b30c9f224fd0e44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0a478b0b724af986aaa1204c818295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609cdab90dcb4ab1834c6bc334c34e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/377M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np  # Added missing import\n",
    "import evaluate\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from transformers import TrainerCallback\n",
    "from transformers import (\n",
    "    VideoMAEImageProcessor,\n",
    "    VideoMAEForVideoClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    default_data_collator,\n",
    "    TrainerCallback,\n",
    ")\n",
    "# Specify the pretrained model checkpoint\n",
    "model_ckpt = \"MCG-NJU/videomae-base\"\n",
    "\n",
    "# Load the image processor\n",
    "image_processor = VideoMAEImageProcessor.from_pretrained(model_ckpt)\n",
    "\n",
    "# Load the VideoMAE model for video classification with 2 labels\n",
    "model = VideoMAEForVideoClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=400,\n",
    "    # label2id=label2id,\n",
    "    # id2label=id2label,\n",
    "    ignore_mismatched_sizes=False,  # Allows adding new classification head\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595ba74d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:24:20.774046Z",
     "iopub.status.busy": "2024-12-12T10:24:20.773489Z",
     "iopub.status.idle": "2024-12-12T12:47:25.076671Z",
     "shell.execute_reply": "2024-12-12T12:47:25.075666Z"
    },
    "papermill": {
     "duration": 8584.313721,
     "end_time": "2024-12-12T12:47:25.080383",
     "exception": false,
     "start_time": "2024-12-12T10:24:20.766662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07b3dbb985b4c05850cc4dd032b59f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 1:06:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>0.664962</td>\n",
       "      <td>0.553333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.682303</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.634500</td>\n",
       "      <td>0.511513</td>\n",
       "      <td>0.776667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.492400</td>\n",
       "      <td>0.368056</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.304700</td>\n",
       "      <td>0.334437</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.230751</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.347311</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.158294</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.391693</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.308792</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 02:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for lr 0.0001: {'train_runtime': 4064.9408, 'train_samples_per_second': 0.59, 'train_steps_per_second': 0.03, 'total_flos': 0.0, 'train_loss': 0.3097060183684031, 'epoch': 10.0}\n",
      "Evaluation results for lr 0.0001: {'eval_loss': 0.1582939624786377, 'eval_accuracy': 0.9466666666666667, 'eval_runtime': 213.3864, 'eval_samples_per_second': 1.406, 'eval_steps_per_second': 0.07, 'epoch': 10.0}\n",
      "Training with learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 1:06:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.685900</td>\n",
       "      <td>0.563333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681600</td>\n",
       "      <td>0.674339</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.646400</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.743333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.630367</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.598600</td>\n",
       "      <td>0.612221</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.594577</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.554900</td>\n",
       "      <td>0.581549</td>\n",
       "      <td>0.796667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>0.572488</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.518200</td>\n",
       "      <td>0.569357</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 02:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for lr 1e-05: {'train_runtime': 4078.2583, 'train_samples_per_second': 0.588, 'train_steps_per_second': 0.029, 'total_flos': 0.0, 'train_loss': 0.6075323621431986, 'epoch': 10.0}\n",
      "Evaluation results for lr 1e-05: {'eval_loss': 0.5693569183349609, 'eval_accuracy': 0.81, 'eval_runtime': 217.9941, 'eval_samples_per_second': 1.376, 'eval_steps_per_second': 0.069, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np  # Added missing import\n",
    "import evaluate\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from transformers import (\n",
    "    VideoMAEImageProcessor,\n",
    "    VideoMAEForVideoClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    default_data_collator,\n",
    "    TrainerCallback,\n",
    ")\n",
    "\n",
    "# Load accuracy metric\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, model, num_labels):\n",
    "        super(CustomClassifier, self).__init__()\n",
    "        self.model = model  # Pre-trained VideoMAE model\n",
    "        self.new_layers = nn.Sequential(\n",
    "            nn.Linear(400, 512),  # Add a linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_labels)  # Final classification layer\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        # The model directly returns logits for classification\n",
    "        outputs = self.model(pixel_values=pixel_values)\n",
    "        logits = self.new_layers(outputs.logits)  # Modify to use logits directly\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "        return {\"logits\": logits}\n",
    "\n",
    "# Define a custom callback to log metrics to MLflow\n",
    "class MLflowCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        metrics = kwargs.get('metrics', {})\n",
    "        if metrics:\n",
    "            epoch = state.epoch\n",
    "            if 'train_loss' in metrics:\n",
    "                mlflow.log_metric(\"train_loss\", metrics.get(\"train_loss\"), step=epoch)\n",
    "            if 'eval_accuracy' in metrics:\n",
    "                mlflow.log_metric(\"eval_accuracy\", metrics.get(\"eval_accuracy\"), step=epoch)\n",
    "            if 'eval_loss' in metrics:\n",
    "                mlflow.log_metric(\"eval_loss\", metrics.get(\"eval_loss\"), step=epoch)\n",
    "\n",
    "# Assuming label2id and id2label are defined\n",
    "# label2id = {\"class0\": 0, \"class1\": 1}\n",
    "# id2label = {0: \"class0\", 1: \"class1\"}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in [1e-4, 1e-5]:  # Example learning rates\n",
    "    with mlflow.start_run(run_name=f\"lr_{lr}\"):\n",
    "        print(f\"Training with learning rate: {lr}\")\n",
    "\n",
    "        # Specify the pretrained model checkpoint\n",
    "        model_ckpt = \"MCG-NJU/videomae-base\"\n",
    "\n",
    "        # Load the image processor\n",
    "        image_processor = VideoMAEImageProcessor.from_pretrained(model_ckpt)\n",
    "\n",
    "        # Load the VideoMAE model for video classification with 2 labels\n",
    "        model = VideoMAEForVideoClassification.from_pretrained(\n",
    "            model_ckpt,\n",
    "            num_labels=400,\n",
    "            # label2id=label2id,\n",
    "            # id2label=id2label,\n",
    "            ignore_mismatched_sizes=False,  # Allows adding new classification head\n",
    "        ).to(device)\n",
    "\n",
    "        # Wrap the model with custom classifier\n",
    "        model = CustomClassifier(model, 2)\n",
    "\n",
    "        # Define training arguments with GPU optimizations\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./video_mae_fight_noFight\",\n",
    "            num_train_epochs=10,\n",
    "            per_device_train_batch_size=10,\n",
    "            per_device_eval_batch_size=10,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=lr,\n",
    "            warmup_ratio=0.1,\n",
    "            logging_steps=10,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            push_to_hub=False,\n",
    "            remove_unused_columns=False,  # Necessary to keep 'pixel_values'\n",
    "            report_to=\"none\",\n",
    "            fp16=True,  # Enable mixed precision training\n",
    "            dataloader_num_workers=4,  # Increase for faster data loading\n",
    "        )\n",
    "\n",
    "        # Instantiate the Trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=hf_train_dataset,\n",
    "            eval_dataset=hf_test_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "            data_collator=default_data_collator,\n",
    "            tokenizer=image_processor,  # Necessary for push_to_hub to include image processor\n",
    "            callbacks=[MLflowCallback()],\n",
    "        )\n",
    "\n",
    "        # Log the learning rate parameter\n",
    "        mlflow.log_param('learning_rate', lr)\n",
    "\n",
    "        # Start training\n",
    "        train_results = trainer.train()\n",
    "\n",
    "        # Log training metrics\n",
    "        train_metrics = train_results.metrics\n",
    "        mlflow.log_metric('train_loss', train_metrics['train_loss'])\n",
    "        if 'train_accuracy' in train_metrics:\n",
    "            mlflow.log_metric('train_accuracy', train_metrics['train_accuracy'])\n",
    "\n",
    "        # Evaluate the model\n",
    "        eval_results = trainer.evaluate()\n",
    "\n",
    "        # Log evaluation metrics\n",
    "        mlflow.log_metric('test_loss', eval_results.get('eval_loss'))\n",
    "        if 'eval_accuracy' in eval_results:\n",
    "            mlflow.log_metric('test_accuracy', eval_results['eval_accuracy'])\n",
    "\n",
    "        print(f\"Training results for lr {lr}: {train_metrics}\")\n",
    "        print(f\"Evaluation results for lr {lr}: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89469c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T12:47:25.111579Z",
     "iopub.status.busy": "2024-12-12T12:47:25.110740Z",
     "iopub.status.idle": "2024-12-12T12:47:25.115294Z",
     "shell.execute_reply": "2024-12-12T12:47:25.114491Z"
    },
    "papermill": {
     "duration": 0.017688,
     "end_time": "2024-12-12T12:47:25.116990",
     "exception": false,
     "start_time": "2024-12-12T12:47:25.099302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08391ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T12:47:25.138195Z",
     "iopub.status.busy": "2024-12-12T12:47:25.137926Z",
     "iopub.status.idle": "2024-12-12T12:47:25.163091Z",
     "shell.execute_reply": "2024-12-12T12:47:25.162152Z"
    },
    "papermill": {
     "duration": 0.038004,
     "end_time": "2024-12-12T12:47:25.164912",
     "exception": false,
     "start_time": "2024-12-12T12:47:25.126908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 12:47:25 INFO mlflow.tracking.fluent: Experiment with name 'VideoMAE_Fight_NoFight_Classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///kaggle/working/mlruns/216868649290100681', creation_time=1734007645157, experiment_id='216868649290100681', last_update_time=1734007645157, lifecycle_stage='active', name='VideoMAE_Fight_NoFight_Classification', tags={}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates=[0.001]\n",
    "# Initialize MLflow\n",
    "mlflow.set_tracking_uri(\"file://\" + os.path.abspath(\"mlruns\"))  # Change as needed\n",
    "mlflow.set_experiment(\"VideoMAE_Fight_NoFight_Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e49aed88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T12:47:25.187422Z",
     "iopub.status.busy": "2024-12-12T12:47:25.186671Z",
     "iopub.status.idle": "2024-12-12T12:47:25.190844Z",
     "shell.execute_reply": "2024-12-12T12:47:25.190088Z"
    },
    "papermill": {
     "duration": 0.016978,
     "end_time": "2024-12-12T12:47:25.192384",
     "exception": false,
     "start_time": "2024-12-12T12:47:25.175406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5825564,
     "sourceId": 9559894,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8768.322412,
   "end_time": "2024-12-12T12:47:29.066835",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-12T10:21:20.744423",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "005b71edc50641ecb64c4ef1da0350f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d8ee00adaad1430bb50c99eb5a1de24f",
       "placeholder": "​",
       "style": "IPY_MODEL_e21984a68392458b8e5f78f1f35b5d3a",
       "value": " 271/271 [00:00&lt;00:00, 26.0kB/s]"
      }
     },
     "0149b693c0a444c4966ee4c344fb25d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_10cacccbc61c41de9a5c5bcf63b697e7",
       "placeholder": "​",
       "style": "IPY_MODEL_02cac4e1f8054e50a4cf4844e6b75e6b",
       "value": " 4.20k/4.20k [00:00&lt;00:00, 456kB/s]"
      }
     },
     "02cac4e1f8054e50a4cf4844e6b75e6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "10cacccbc61c41de9a5c5bcf63b697e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "130ddcbf9217462293458d46fd265e5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1676d54c30364f1fba5f3961d1d45797": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ffb4d9dd8dd4ec988ea5b0ae32a840a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7b0beec4c46d4f69aae86559bf190b32",
       "max": 4203.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_45565b2336c24bd99b819adf0f70be83",
       "value": 4203.0
      }
     },
     "2c0dea52fc0342ec923990164aa10db2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e86422789454d33a1d861fb83b17092": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "35d972b36af443358b86d83d0b26ac92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3e95477369d344bbab7efacf573d4bee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "44abaf413af6412cbe87896e51f5bed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "45565b2336c24bd99b819adf0f70be83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "55d672cef6a64c64a0450a6629ae2c7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2c0dea52fc0342ec923990164aa10db2",
       "placeholder": "​",
       "style": "IPY_MODEL_738317249e864d4e9d63f05de86772c5",
       "value": "Downloading builder script: 100%"
      }
     },
     "59c805afe8184f4e809a19133aee557e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a0dadf3367a48b3a8d16713eb8c72de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1676d54c30364f1fba5f3961d1d45797",
       "placeholder": "​",
       "style": "IPY_MODEL_44abaf413af6412cbe87896e51f5bed7",
       "value": "model.safetensors: 100%"
      }
     },
     "5c19d37ab8d243bda9e2f7a85e3406bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5d0dab22aaa64de0b04b3d6583a064a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f9854fc3fd094616a090b81bd0ce525d",
       "placeholder": "​",
       "style": "IPY_MODEL_5c19d37ab8d243bda9e2f7a85e3406bf",
       "value": " 725/725 [00:00&lt;00:00, 77.7kB/s]"
      }
     },
     "609cdab90dcb4ab1834c6bc334c34e81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5a0dadf3367a48b3a8d16713eb8c72de",
        "IPY_MODEL_911004b5fa284ab496551b4f2ea0599f",
        "IPY_MODEL_6f66564f47524a4eb03ef3bf6efab4c5"
       ],
       "layout": "IPY_MODEL_ddbdfeb6e08f45b389b189faca5114be"
      }
     },
     "6d0a365b189540039e29160694c05cdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6f66564f47524a4eb03ef3bf6efab4c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fcf6ddb1d30c4c939319e538160ee6f5",
       "placeholder": "​",
       "style": "IPY_MODEL_6d0a365b189540039e29160694c05cdd",
       "value": " 377M/377M [00:01&lt;00:00, 249MB/s]"
      }
     },
     "738317249e864d4e9d63f05de86772c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7b0beec4c46d4f69aae86559bf190b32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f3d5293a33d4e9986373a27499c78cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "911004b5fa284ab496551b4f2ea0599f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a89fb43163be4c7bae9c015d7bb65ed1",
       "max": 376873760.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2e86422789454d33a1d861fb83b17092",
       "value": 376873760.0
      }
     },
     "9149a1cb75c146f190fa18920491dce4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a89fb43163be4c7bae9c015d7bb65ed1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8d8e96582a3491cbd4b29a4b641e008": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b626d87f39a3464d8163105f33c77aae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf952ffd9e1d4856ae7a3fcbb268805a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f3d5293a33d4e9986373a27499c78cf",
       "max": 725.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_35d972b36af443358b86d83d0b26ac92",
       "value": 725.0
      }
     },
     "d8113efcc0054dd2beacff614d652b8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8ee00adaad1430bb50c99eb5a1de24f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "da3f7a5657b445e49b4b61b54fafdd12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f746727c06aa474abd853221ac85b689",
       "placeholder": "​",
       "style": "IPY_MODEL_3e95477369d344bbab7efacf573d4bee",
       "value": "preprocessor_config.json: 100%"
      }
     },
     "db0a478b0b724af986aaa1204c818295": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fcc2076a99df4b5688ba15c5bde14b9e",
        "IPY_MODEL_bf952ffd9e1d4856ae7a3fcbb268805a",
        "IPY_MODEL_5d0dab22aaa64de0b04b3d6583a064a1"
       ],
       "layout": "IPY_MODEL_a8d8e96582a3491cbd4b29a4b641e008"
      }
     },
     "dbfd45b868a74c6db5d7d48dfea84886": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ddbdfeb6e08f45b389b189faca5114be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e21984a68392458b8e5f78f1f35b5d3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ea30b3cd28c74974b30c9f224fd0e44b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_da3f7a5657b445e49b4b61b54fafdd12",
        "IPY_MODEL_f985360bec95494a8f47ee2148e64a30",
        "IPY_MODEL_005b71edc50641ecb64c4ef1da0350f9"
       ],
       "layout": "IPY_MODEL_59c805afe8184f4e809a19133aee557e"
      }
     },
     "f07b3dbb985b4c05850cc4dd032b59f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_55d672cef6a64c64a0450a6629ae2c7b",
        "IPY_MODEL_1ffb4d9dd8dd4ec988ea5b0ae32a840a",
        "IPY_MODEL_0149b693c0a444c4966ee4c344fb25d3"
       ],
       "layout": "IPY_MODEL_dbfd45b868a74c6db5d7d48dfea84886"
      }
     },
     "f746727c06aa474abd853221ac85b689": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f985360bec95494a8f47ee2148e64a30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d8113efcc0054dd2beacff614d652b8a",
       "max": 271.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_130ddcbf9217462293458d46fd265e5d",
       "value": 271.0
      }
     },
     "f9854fc3fd094616a090b81bd0ce525d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fcc2076a99df4b5688ba15c5bde14b9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b626d87f39a3464d8163105f33c77aae",
       "placeholder": "​",
       "style": "IPY_MODEL_9149a1cb75c146f190fa18920491dce4",
       "value": "config.json: 100%"
      }
     },
     "fcf6ddb1d30c4c939319e538160ee6f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
